{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\nDevelopment\nThis package is developed by researchers at FHI.(TO BE FILLED IN)\nHow to contact us\nIf you have any questions about our privacy policy, or you would like to exercise one of your data protection rights, please do not hesitate to contact us.\nEmail us at: sykdomspulsen@fhi.no\nPrivacy\nThis privacy policy will explain how Sykdomspulsen uses the personal data we collect from you when you use our website for technical documentation (sykdomspulsen-dokumentasjon.no).\nWhat data do we collect?\nOn sykdomspulsen-dokumentasjon.no we do not collect any information.\nCookies\nCookies are text files placed on your computer to collect standard Internet log information and visitor behavior information. For further information, visit allaboutcookies.org.\nHow do we use cookies?\nWe do not use cookies.\nChanges to our privacy policy\nWe keep our privacy policy under regular review and places any updates on this web page. This privacy policy was last updated on 2020-02-25\nHow to contact the appropriate authority\nShould you wish to report a complaint or if you feel that we have not addressed your concern in a satisfactory manner, you may contact datatilsynet at https://www.datatilsynet.no/om-datatilsynet/kontakt-oss/\n\n\n\n",
      "last_modified": "2020-12-25T19:59:53+01:00"
    },
    {
      "path": "example.html",
      "title": "Examples",
      "description": "An example",
      "author": [],
      "date": "12/23/2020",
      "contents": "\nWeather\nWe will now work our way through an example implementation of a weather surveillance system.\nDatabase table/schema\nTo begin with, we need to create a database table schema that describes the final database table that we will store the information that we will collect.\n\n\nsc::add_schema(\n  name = \"example_weather\",\n  schema = sc::Schema$new(\n    db_config = sc::config$db_config,\n    db_table = \"example_weather\",\n    db_field_types =  c(\n      \"granularity_time\" = \"TEXT\",\n      \"granularity_geo\" = \"TEXT\",\n      \"location_code\" = \"TEXT\",\n      \"border\" = \"INTEGER\",\n      \"age\" = \"TEXT\",\n      \"sex\" = \"TEXT\",\n      \"year\" = \"INTEGER\",\n      \"week\" = \"INTEGER\",\n      \"yrwk\" = \"TEXT\",\n      \"season\" = \"TEXT\",\n      \"x\" = \"DOUBLE\",\n      \"date\" = \"DATE\",\n\n      \"tg\" = \"DOUBLE\",\n      \"tx\" = \"DOUBLE\",\n      \"tn\" = \"DOUBLE\",\n      \"rr\" = \"DOUBLE\"\n    ),\n    db_load_folder = tempdir(),\n    keys =  c(\n      \"location_code\",\n      \"date\"\n    ),\n    validator_field_types = sc::validator_field_types_sykdomspulsen,\n    validator_field_contents = sc::validator_field_contents_sykdomspulsen\n  )\n)\n\n\n\nThis schema has a few main parts.\nname is an internal reference that we will use to access this database table at sc::config$schemas$example_weather.\ndb_config is a list that contains information about the database:\n\n\nnames(sc::config$db_config)\n\n\n\ndb_table is the name of the database table in the database.\ndb_field_types is a vector containing the names and variable types of the columns of the database table.\nkeys are the columns that will form the primary key of the databse (i.e. identify unique rows).\nvalidator_field_types is a validator that is useful for ensuring that your database table names are consistent with predetermined rules. For example, in Sykdomspulsen we have decided that we always want the first 12 columns to be granularity_time, granularity_geo, location_code, border, age, sex, year, week, yrwk, season, x, date. However, while developing new code we found that it was difficult to force all developers to remember to include these 12 columns in the correct order. The validator sc::validator_field_types_sykdomspulsen ensures that the first 12 columns are as expected, and otherwise the developer will not be able to run their code.\nvalidator_field_contents is a validator that ensures that the contents of your data is correct. We experienced that there were issues with granularity_time sometimes containing the value week and sometimes containing the value weekly. To maintain consistency in our data, the validator sc::validator_field_contents_sykdomspulsen will throw an error if it observes non-accepted values for certain variables.\nTask\nWe now need to create a task that will download the data from an API, clean it, and store it in the database schema.\nFor simple tasks we can use the convenience function sc::task_from_config.\n\n\nsc::add_task(\n  sc::task_from_config(\n    name = \"example_weather\",\n    type = \"data\",\n    action = \"example_weather\",\n    schema = list(output = sc::config$schemas$example_weather)\n  )\n)\n\n\n\nname is an internal name that we will use to reference the task.\ntype is one of data, analysis, ui, or single.\naction is the function that will be called.\nschema is a list containing schemas.\nAction\nWe now need to develop the action example_weather. We do this by creating an R function that contains 3 arguments:\n\n\ndatar_weather <- function(data, argset, schema) {\n  # sc::tm_run_task(\"example_weather\")\n\n  if(plnr::is_run_directly()){\n    data <- sc::tm_get_data(\"example_weather\")\n    argset <- sc::tm_get_argset(\"example_weather\")\n    schema <- sc::tm_get_schema(\"example_weather\")\n  }\n  \n  # download the forecast for Oslo\n  a <- httr::GET(glue::glue(\"https://api.met.no/weatherapi/locationforecastlts/1.3/?lat=59.9&lon=10.8\"), httr::content_type_xml())\n  a <- xml2::read_xml(a$content)\n\n  baz <- xml2::xml_find_all(a, \".//maxTemperature\")\n  res <- vector(\"list\", length = length(baz))\n  for (i in seq_along(baz)) {\n    parent <- xml2::xml_parent(baz[[i]])\n    grandparent <- xml2::xml_parent(parent)\n    time_from <- xml2::xml_attr(grandparent, \"from\")\n    time_to <- xml2::xml_attr(grandparent, \"to\")\n    x <- xml2::xml_find_all(parent, \".//minTemperature\")\n    temp_min <- xml2::xml_attr(x, \"value\")\n    x <- xml2::xml_find_all(parent, \".//maxTemperature\")\n    temp_max <- xml2::xml_attr(x, \"value\")\n    x <- xml2::xml_find_all(parent, \".//precipitation\")\n    precip <- xml2::xml_attr(x, \"value\")\n\n    res[[i]] <- data.frame(\n      time_from = as.character(time_from),\n      time_to = as.character(time_to),\n      tx = as.numeric(temp_max),\n      tn = as.numeric(temp_min),\n      rr = as.numeric(precip)\n    )\n  }\n  res <- rbindlist(res)\n  res <- res[stringr::str_sub(time_from, 12, 13) %in% c(\"00\", \"06\", \"12\", \"18\")]\n  res[, date := as.Date(stringr::str_sub(time_from, 1, 10))]\n  res[, N := .N, by = date]\n  res <- res[N == 4]\n  res <- res[, .(\n    tg = NA,\n    tx = max(tx),\n    tn = min(tn),\n    rr = sum(rr)\n  ),\n  keyby = .(date)\n  ]\n  \n  # we look at the downloaded data\n  print(res)\n  \n  # we now need to format it\n  res[, granularity_time := \"day\"]\n  res[, granularity_geo := \"county\"]\n  res[, location_code := \"county03\"]\n  res[, border := 2020]\n  res[, age := \"total\"]\n  res[, sex := \"total\"]\n  res[, year := fhi::isoyear_n(date)]\n  res[, week := fhi::isoweek_n(date)]\n  res[, yrwk := fhi::isoyearweek(date)]\n  res[, season := fhi::season(yrwk)]\n  res[, x := fhi::x(week)]\n  \n  # upload it to the database\n  schema$output$db_upsert_load_data_infile(res)\n}\n\n\n\nIt is important to pay attention to the lines at the top of the function:\nif(plnr::is_run_directly()){\n  data <- sc::tm_get_data(\"example_weather\")\n  argset <- sc::tm_get_argset(\"example_weather\")\n  schema <- sc::tm_get_schema(\"example_weather\")\n}\nThese lines allow a person to run the code interactively from directly inside the function, without running any prior “setup” code. This means that if a person wants to develop or debug a particular task, they can work directly inside that task, without “going to file X, running lines A, B, C, going to file Y, running lines D, E, F, …”. Instead, they can treat the task function like an independent R script.\nThis has large benefits, as it means that:\nmore advanced R programmers can work with the broader “infrastructure” (setting up database schema, tasks)\nless-advanced R programmers can work within a task that has already been set up (e.g. modifying it as if it were a simple independent R script)\nThis means that resources can be used most effectively, with advanced programmers working on the difficult tasks, with less-advanced programmers assisting in areas where they can (without the need for them to understand the more complicated aspects)\nRunning the task\nThe following command is used to run the task from within R:\nsc::tm_run_task(\"example_data\")\nAccessing the data\nWe can easily access data from the database via the helper function sc::tbl and subsequent dplyr (https://dplyr.tidyverse.org/) functions:\n\n\nsc::tbl(\"example_weather\") %>%\n  dplyr::collect()\n\n\n\n\n\n\n",
      "last_modified": "2020-12-25T19:59:56+01:00"
    },
    {
      "path": "index.html",
      "title": "Sykdomspulsen",
      "description": "The Norwegian syndromic surveillance system (TEMPORARY)\n",
      "author": [],
      "contents": "\nSykdomspulsen is a free and open-source health surveillance system. This website contains technical documentation of the infrastructure and statistical methods used in Sykdomspulsen.\n\n\n\n",
      "last_modified": "2020-12-25T19:59:57+01:00"
    },
    {
      "path": "orchestration.html",
      "title": "Orchestration",
      "author": [],
      "date": "12/25/2020",
      "contents": "",
      "last_modified": "2020-12-25T19:59:57+01:00"
    },
    {
      "path": "philosophy.html",
      "title": "Philosophy",
      "author": [],
      "contents": "",
      "last_modified": "2020-12-25T20:00:00+01:00"
    },
    {
      "path": "tables.html",
      "title": "Tables",
      "description": "Tables ",
      "author": [],
      "contents": "\nUnified variables\nAll accessible tables will contain these variables.\n\n\nVariables\n\n\nType\n\n\nAccepted values\n\n\nDescription\n\n\ngranularity_time\n\n\nText\n\n\ntotal, year, month, week, day, hour\n\n\nTemporal granularity\n\n\ngranularity_geo\n\n\nText\n\n\nnation, county, municip, station\n\n\nGeographical granularity\n\n\nlocation_code\n\n\nText\n\n\nnorge, countyXX, municipXX, stationXX\n\n\nThe geographical location\n\n\nborder\n\n\nInteger\n\n\n2019, 2020\n\n\nThe borders (kommunesammenslåing) that location_code represents\n\n\nage\n\n\nText\n\n\ne.g. 0, 1, 2, 0-4, 5-14, total\n\n\nAge in years\n\n\nsex\n\n\nText\n\n\nmale, female, total\n\n\nSex\n\n\nyear\n\n\nInteger\n\n\nYYYY\n\n\nUse function fhi::isoyear_n\n\n\nweek\n\n\nInteger\n\n\n0, 1, 2, …, 53\n\n\nUse function fhi::isoweek_n\n\n\nyrwk\n\n\nText\n\n\nYYYY-WW\n\n\nUse function fhi::isoyearweek\n\n\nseason\n\n\nText\n\n\ne.g. 2014/2015, 2014/2014, 2014\n\n\nWinter seasons are denoted by 2014/2015 (generally three options: weeks 30-29, weeks 40-20, or weeks 40-39), summer seasons are denoted by 2014/2014 (generally weeks 21-39), years are denoted by the year.\n\n\nx\n\n\nDouble\n\n\n1, 2, 3, …, 23, 23.5, 24, …, 52\n\n\nUse function fhi::x\n\n\ndate\n\n\nDate\n\n\nYYYY-MM-DD\n\n\nAlways corresponds to the last date in the time period. E.g. if granularity_time=='week' then date is the Sunday of that week. fhidata::days is useful here.\n\n\nSuggested variable names\nThese are suggested variables name in an attempt to keep naming consistent across all tables.\n\n\nVariables\n\n\nType\n\n\nAccepted values\n\n\nDescription\n\n\nlocation_name\n\n\nText\n\n\nsykdomspulsen::norway_locations()\n\n\n\n\nmunicip_code\n\n\nText\n\n\nmunicipXX\n\n\n\n\nlocation_name\n\n\nText\n\n\nsykdomspulsen::norway_locations()\n\n\n\n\ntag_outcome\n\n\nText\n\n\n\n\nA descriptor of the outcome\n\n\ntag_exposure\n\n\nText\n\n\n\n\nA descriptor of the exposure\n\n\nweekly_denominator_function\n\n\nText\n\n\nsum, mean\n\n\n\n\nuuid\n\n\nText\n\n\n\n\n\n\nforecast\n\n\nBoolean\n\n\nTrue, False\n\n\nIs it a forecast?\n\n\nX (see below)\n\n\n\n\ncum_excess, point_excess, n, ncor, cum_n, pr100, est, baseline\n\n\nCumulative excess, point excess, n (consultations, deaths), corrected n, X per 100, estimate, baseline\n\n\nX_obs\n\n\nDouble\n\n\n\n\nObserved value\n\n\nX_est\n\n\nDouble\n\n\n\n\nEstimated value\n\n\nX_lower\n\n\nDouble\n\n\n\n\nLower prediction/confidence interval of the estimated value\n\n\nX_upper\n\n\nDouble\n\n\n\n\nLower prediction/confidence interval of the estimated value\n\n\nX_expected\n\n\nDouble\n\n\n\n\nExpected value\n\n\nX_thresholdu_0\n\n\nDouble\n\n\n\n\nGenerally upper threshold zscore=2, mem=low\n\n\nX_thresholdu_1\n\n\nDouble\n\n\n\n\nGenerally upper threshold zscore=4, mem=medium\n\n\nX_thresholdu_2\n\n\nDouble\n\n\n\n\nAs needed\n\n\nX_thresholdu_3\n\n\nDouble\n\n\n\n\nAs needed\n\n\nX_thresholdu_4\n\n\nDouble\n\n\n\n\nAs needed\n\n\nX_thresholdu_5\n\n\nDouble\n\n\n\n\nAs needed\n\n\nX_thresholdl_0\n\n\nDouble\n\n\n\n\nGenerally lower threshold zscore=2\n\n\nX_thresholdl_1\n\n\nDouble\n\n\n\n\nGenerally lower threshold zscore=4\n\n\nX_status\n\n\nText\n\n\nnormal, medium, high, mem=very_low, low, medium, high, very_high\n\n\nStatus\n\n\nX_denominator\n\n\nDouble\n\n\n\n\nDenominator. Generally used if X=pr100 (i.e. a rate per 100)\n\n\nX_zscore\n\n\nDouble\n\n\n\n\nZ-score\n\n\n\n\n\n",
      "last_modified": "2020-12-25T20:00:01+01:00"
    }
  ],
  "collections": []
}
